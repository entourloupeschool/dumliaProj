{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.2.2-cp311-cp311-macosx_10_9_x86_64.whl (9.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/in_vite/Library/Python/3.11/lib/python/site-packages (from scikit-learn) (1.24.3)\n","Collecting scipy>=1.3.2\n","  Downloading scipy-1.10.1-cp311-cp311-macosx_10_9_x86_64.whl (35.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m251.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n","\u001b[?25hCollecting joblib>=1.1.1\n","  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m75.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n","Successfully installed joblib-1.2.0 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# install sklearn\n","%pip install scikit-learn"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-13T18:57:18.731913Z","iopub.status.busy":"2023-05-13T18:57:18.731526Z","iopub.status.idle":"2023-05-13T18:57:24.217950Z","shell.execute_reply":"2023-05-13T18:57:24.216795Z","shell.execute_reply.started":"2023-05-13T18:57:18.731884Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","import torch\n","import torchvision.transforms as transforms\n","import torchvision.transforms.v2 as transformsv2\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.io import read_video\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-13T18:57:28.505424Z","iopub.status.busy":"2023-05-13T18:57:28.505050Z","iopub.status.idle":"2023-05-13T18:57:28.515770Z","shell.execute_reply":"2023-05-13T18:57:28.514696Z","shell.execute_reply.started":"2023-05-13T18:57:28.505394Z"},"trusted":true},"outputs":[],"source":["class UCF101Dataset(Dataset):\n","    def __init__(self, video_list, labels, root_dir, transform=None):\n","        self.video_list = video_list\n","        self.labels = labels\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.video_list)\n","\n","    def __getitem__(self, idx):\n","        video_name = self.video_list[idx]\n","        label = self.labels[video_name]\n","        video_path = os.path.join(self.root_dir, video_name)\n","        video_frames, _, _ = read_video(video_path, pts_unit=\"sec\")\n","\n","        if self.transform:\n","            video_frames = torch.stack([self.transform(frame) for frame in video_frames])\n","\n","        return video_frames, label"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-13T18:57:32.902568Z","iopub.status.busy":"2023-05-13T18:57:32.902140Z","iopub.status.idle":"2023-05-13T18:57:39.587743Z","shell.execute_reply":"2023-05-13T18:57:39.586960Z","shell.execute_reply.started":"2023-05-13T18:57:32.902535Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'projet/data/UCF101'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m labels \u001b[39m=\u001b[39m {}\n\u001b[1;32m      6\u001b[0m videos \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m action_folder \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(root_dir):\n\u001b[1;32m      9\u001b[0m     action_folder_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root_dir, action_folder)\n\u001b[1;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(action_folder_path):\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'projet/data/UCF101'"]}],"source":["# Load the dataset\n","root_dir = \"projet/data/UCF101\"\n","\n","# Assign labels to the videos\n","labels = {}\n","videos = []\n","\n","for action_folder in os.listdir(root_dir):\n","    action_folder_path = os.path.join(root_dir, action_folder)\n","    \n","    if os.path.isdir(action_folder_path):\n","        for video in os.listdir(action_folder_path):\n","            video_path = os.path.join(action_folder_path, video)\n","            \n","            if os.path.isfile(video_path):\n","                labels[video_path] = action_folder\n","                videos.append(video_path)\n","\n","# Create train-test splits\n","train_videos, test_videos = train_test_split(videos, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-13T18:57:39.590073Z","iopub.status.busy":"2023-05-13T18:57:39.589488Z","iopub.status.idle":"2023-05-13T18:57:39.599558Z","shell.execute_reply":"2023-05-13T18:57:39.597719Z","shell.execute_reply.started":"2023-05-13T18:57:39.590040Z"},"trusted":true},"outputs":[],"source":["#Resize\n","resize = 112\n","\n","# Color Jetter transformation\n","coljit = 0.1\n","\n","# normalization parameters\n","mean = (0.5, 0.5, 0.5)\n","std = (0.5, 0.5, 0.5)\n","\n","inner_transforms = transformsv2.Compose([\n","    transformsv2.Resize(resize),\n","    transformsv2.Normalize(mean, std),\n","    transformsv2.ToImageTensor(),\n","    transformsv2.ConvertImageDtype(torch.float32)\n","])\n","\n","outer_transforms = transformsv2.Compose([\n","    transformsv2.RandomHorizontalFlip(),\n","    transformsv2.ColorJitter(brightness=coljit, contrast=coljit, saturation=coljit, hue=coljit),\n","])\n","\n","# define the v2 transformations to be applied to the images\n","transform_val = transforms.Compose([\n","    inner_transforms\n","])\n","\n","transform_train = transforms.Compose([\n","    outer_transforms,\n","    inner_transforms\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["selected_actions = ['ApplyEyeMakeup', 'BenchPress', 'CliffDiving']  # Replace these with the actual action names you want to keep\n","\n","filtered_train_videos = [video_path for video_path in train_videos if labels[video_path] in selected_actions]\n","filtered_train_labels = [label for label in labels if label in selected_actions]\n","\n","filtered_test_videos = [video_path for video_path in test_videos if labels[video_path] in selected_actions]\n","filtered_test_labels = [label for label in labels if label in selected_actions]\n","\n","# Create the train and test datasets\n","train_dataset = UCF101Dataset(filtered_train_videos, filtered_train_labels, root_dir, transform_train)\n","test_dataset = UCF101Dataset(filtered_test_videos, filtered_test_labels, root_dir, transform_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-13T19:00:08.832454Z","iopub.status.idle":"2023-05-13T19:00:08.832962Z","shell.execute_reply":"2023-05-13T19:00:08.832766Z","shell.execute_reply.started":"2023-05-13T19:00:08.832730Z"},"trusted":true},"outputs":[],"source":["batch_size = 2\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T05:51:42.227008Z","iopub.status.busy":"2023-05-05T05:51:42.226105Z","iopub.status.idle":"2023-05-05T05:51:43.058859Z","shell.execute_reply":"2023-05-05T05:51:43.057905Z","shell.execute_reply.started":"2023-05-05T05:51:42.226970Z"},"trusted":true},"outputs":[],"source":["import torchvision.models as models\n","\n","# Load the pre-trained 3D ResNet-18 model\n","r3d_18 = models.video.r3d_18(weights='DEFAULT')\n","\n","# Remove the last fully connected layer to use the model for feature extraction\n","r3d_18 = torch.nn.Sequential(*list(r3d_18.children())[:-1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
